{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d258e95-a2a3-4bb8-a5cd-cf15d0b7d256",
   "metadata": {},
   "source": [
    "# Final Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ae892a-341f-44cf-9652-e85c76b8e916",
   "metadata": {},
   "source": [
    "## Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18923065-8a0b-4b71-8fb5-4c85180c78f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0c6d3e2a-6ade-4aad-b42f-e00e40d43e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score, roc_auc_score\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score\n",
    "from sklearn import svm\n",
    "\n",
    "import optuna\n",
    "\n",
    "from lightgbm import LGBMClassifier, LGBMRanker\n",
    "from catboost import CatBoostClassifier, CatBoostRanker\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d3f6c1b-98df-4f68-b63e-00a85db325f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA Imports\n",
    "from src.eda import null_columns_checker, column_investigator, find_unique_values, analyser_generic, tree_path_investigator\n",
    "from src.eda import non_numeric_check, dimension_investigator\n",
    "\n",
    "# FE Imports\n",
    "from src.fe import indicate_nulls, fuzzy_search, dynamic_check_text, check_columns_on_query, check_columns_on_text \n",
    "from src.fe import dim_binner, check_columns_on_dim, column_dropper, add_new_features\n",
    "\n",
    "# Feature Model Selectin Imports\n",
    "from src.feature_model_selection import find_high_corr_pairs, manual_pr_draw, manual_auc_roc_draw, groupper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff0012d6-3cc1-4dca-b1ca-80107956322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_file_path= 'data/train.feather'\n",
    "ori_train_df = pd.read_feather(train_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7292aeaf-cd53-410f-a09f-bd5e567ccc2c",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c27db0e5-24fc-4f36-9f07-1fc43c66dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(test_size=0.2, random_state=42).split(ori_train_df, groups=ori_train_df['query'])\n",
    "X_train_inds, X_val_inds = next(gss)\n",
    "\n",
    "train_df = ori_train_df.iloc[X_train_inds]\n",
    "X_train = train_df.loc[:, ~train_df.columns.isin(['is_relevant'])]\n",
    "y_train = train_df.loc[:, train_df.columns.isin(['is_relevant'])]\n",
    "\n",
    "#We need to keep the query fo2r later predictions\n",
    "val_df = ori_train_df.iloc[X_val_inds]\n",
    "X_val = val_df.loc[:, ~val_df.columns.isin(['is_relevant'])]\n",
    "y_val = val_df.loc[:, val_df.columns.isin(['is_relevant'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7326c6-20a8-48fb-a916-335d9e874ccb",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "71ab56fc-6ffb-4851-a316-0c9d7dbbb811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null_check_columns:  ['alt', 'sizes', 'class']\n",
      "columns_to_drop:  ['crossorigin', 'ismap', 'longdesc', 'referrerpolicy']\n",
      "Successfully dropping fully Null columns!\n",
      "\n",
      "Successfully indicating partially Null columns!\n",
      "\n",
      "Successfully adding text-based features!\n",
      "\n",
      "Successfully adding url-based features!\n",
      "\n",
      "rel_feature_potential:  ['figure', 'p', 'source']\n",
      "irrel_feature_potential:  ['a']\n",
      "Total Data covered: 47.4%\n",
      "Successfully adding first tree-path feature!\n",
      "\n",
      "rel_feature_potential:  ['figure', 'p', 'amp-img', 'getpreference', 'readme-toc', 'treasure-overlay-spinner', 'pre', 'task-lists', 'textarea', 'app-pharmacy-layout', 'tw-wrapper', 'app-project-detail', 'ps-carousel', 'bpc-app', 'z-widget', 'bpc-product', 'app-modal', 'swiper', 'brb', 'cont', 'object', 'app-photo-wall', 'rs-layer', 'app-product', 'titles', 'app-person', 'b-container', 'bpc-dynamic-view-carousel', 'bpc-product-card-base', 'enx-image', 'bpc-other-products-base', 'bpc-product-card-image', 'app-medicine-detail', 'flo-root', 'flo-header-layout', 'app-product-detail', 'ion-app', 'ion-router-outlet', 'app-product-page', 'cut', 'ion-content', 'ppc-content', 'devsite-content', 'ppc-container', 'articles', 'bodyclass', 'index', 'app-screenshot-wrapper', 'slider', 'app-screenshot-gallery', 'play-blog', 'app-person-header', 'tab-list', 'flo-collection', 'lazy-hydrate', 'hero-image', 'spand', 'app-credits', 'single-item', 'article-content-flex2019', 'tab-item', 'mospace-heroarea', 'ps-article-page', 'articleclass', 'ps-storystack-page', 'hybrid-details-image', 'ps-articlepage', 'app-product-sheet-preview-pages', 'ecfe-app-root', 'app-product-sheet-preview', 'core-image-loader', 'school-data', 'mem-memorial', 'app-meme-ready', 'mem-banner', 'app-news-details', 'app-create-meme', 'af-more-images-link', 'registration', 'ps-liveblog', 'xref']\n",
      "irrel_feature_potential:  ['a', 'li', 'ul', 'footer', 'aside', 'nav', 'ol', 'head', 'dl', 'yelp-react-root', 'dd', 'label', 'template', 'dt', 'i', 'wix-image', 'h4', 'phoenix-super-link', 'phoenix-card', 'phoenix-hub', 'ng-component', 'chrome', 'entity-v2', 'mat-sidenav-content', 'page-layout', 'mat-sidenav-container', 'wrapper', 'mat-card', 'page-centered-layout', 'section-card', 'cb-image', 'row-card', 'profile-section', 'hub-list-card', 'phoenix-non-personalized-recommendations-tracking', 'phoenix-recommendations', 'footer-links', 'component', 'searchbox', 'app-image', 'app-photos-list', 'app-search-page', 'header-side-panels', 'epic-website', 'epic-book', 'app-book', 'h6', 'module', 'rccl-product-view-itinerary', 'rccl-product-view', 'rccl-product-view-deferred-load-image', 'epic-book-row', 'rccl-product-view-itinerary-chapter', 'small', 'code', 'csobj', 'wb-slider', 'sidebar', 'infosheet-section', 'iframe', 'column', 'rccl-product-view-mosaic', 'pyramid-level', 'pyramid-switch', 'pane', 'google-site-verification:', 'book-similar-carousel', 'ngu-carousel', 'transition', 'sup', 'product', 'wix-bg-media', 'book-popular-carousel', 'output', 'dfn', 'app-meta-more-section', 'bpc-mobile-menu-navigation-base', 'bpc-page-element-wrapper', 'app-meta-details', 'bpc-mobile-menu-content-base', 'bpc-accordion-shelf', 'bpc-dynamic-html', 'bpc-accordion', 'main-menu-flyout', 'box', 'app-player', 'hg-accordion', 'boxes', 'app-header', 'widget']\n",
      "Total Data covered: 151.0%\n",
      "Successfully adding overall tree-path feature!\n",
      "\n",
      "rel_feature_potential:  ['figure', 'article']\n",
      "irrel_feature_potential:  ['a', 'li', 'body']\n",
      "Total Data covered: 24.8%\n",
      "Successfully adding text-tag feature!\n",
      "\n",
      "rel_feature_potential:  ['400 - Max']\n",
      "irrel_feature_potential:  ['Min - 150']\n",
      "Total Data covered: 25.8%\n",
      "Successfully adding height-based feature!\n",
      "\n",
      "rel_feature_potential:  [1.0, 3.0, 4.0]\n",
      "irrel_feature_potential:  []\n",
      "Total Data covered: 1.5%\n",
      "Successfully adding sizes-based feature!\n",
      "\n",
      "rel_feature_potential:  [3.0, 4.0, 6.0, 7.0, 8.0, 9.0, 10.0, 14.0]\n",
      "irrel_feature_potential:  [1.0]\n",
      "Total Data covered: 8.4%\n",
      "Successfully adding srcset-based feature!\n",
      "\n",
      "rel_feature_potential:  ['350 - Max']\n",
      "irrel_feature_potential:  ['Min - 150']\n",
      "Total Data covered: 27.0%\n",
      "Successfully adding width-based feature!\n",
      "\n",
      "rel_feature_potential:  ['attachment-large size-large', 'ZKyw4m_g2d_2ig6XJbKp', 'attachment-full size-full', 'attachment-post-thumbnail size-post-thumbnail wp-post-image']\n",
      "irrel_feature_potential:  ['attachment-woocommerce_thumbnail size-woocommerce_thumbnail', 'MosaicAsset-module__thumb___epLhd', 'item-img', 'thumb', 'entry-thumb', 'avatar ', 'crp_thumb crp_featured', 'ipc-image', 'WebsiteImageSmall', 'landscape', 'lazy', 'lazyOwl imgdescription', 'nav-team-logo', 'post-image', 'pricelist_zoom', 'ResponsiveImageContainer-dlOMGF byslZC responsive-image__image', 'thumbborder', '_3VqQ_', 'attachment-medium size-medium wp-post-image', 'img--noscript card__img ', 'h-8 bg-white rounded mr-2 mt-2 last:mr-0', 'a-dynamic-image', ' css-xlzvdl', 'avatar avatar-48 photo', 'a-dynamic-image p13n-sc-dynamic-image p13n-product-image', 'attachment-thumbnail size-thumbnail wp-post-image', 'attachment-thumbnail size-thumbnail', 'd-block']\n",
      "Total Data covered: 8.8%\n",
      "Successfully adding class-based feature!\n",
      "\n",
      "rel_feature_potential:  ['']\n",
      "irrel_feature_potential:  ['display:none;', 'width:92px;height:92px;object-fit:cover;object-position:25% 25%', 'display:none', 'max-width: 100%; height: auto;', 'max-width:64px;max-height:64px', 'height: 100%;', 'max-height:50px;max-width:50px;', 'max-width:160px;max-height:160px']\n",
      "Total Data covered: 4.9%\n",
      "Successfully adding style-based feature!\n",
      "\n",
      "Successfully removing high correlated features!\n",
      "\n",
      "Successfully reordering columns!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_output = add_new_features(train_df, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3bebeb28-2949-44b1-bc70-034be374acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fe = train_output.pop(0)\n",
    "val_inputs = train_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b93f20cb-d67f-4f07-8f9c-30f26d05dde4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully dropping fully Null columns!\n",
      "\n",
      "Successfully indicating partially Null columns!\n",
      "\n",
      "Successfully adding text-based features!\n",
      "\n",
      "Successfully adding url-based features!\n",
      "\n",
      "Successfully adding first tree-path feature!\n",
      "\n",
      "Successfully adding overall tree-path feature!\n",
      "\n",
      "Successfully adding text-tag feature!\n",
      "\n",
      "Successfully adding height-based feature!\n",
      "\n",
      "Successfully adding sizes-based feature!\n",
      "\n",
      "Successfully adding srcset-based feature!\n",
      "\n",
      "Successfully adding width-based feature!\n",
      "\n",
      "Successfully adding class-based feature!\n",
      "\n",
      "Successfully adding style-based feature!\n",
      "\n",
      "Successfully removing high correlated features!\n",
      "\n",
      "Successfully reordering columns!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_output = add_new_features(val_df, 'val', val_inputs)\n",
    "X_val_fe = val_output.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e194ac11-d685-4b30-9123-efd87488c06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns from X_train_fe:  []\n",
      "Missing columns from X_val_fe:  []\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing columns from X_train_fe: \", [col for col in val_fe.columns if col not in X_train_fe.columns])\n",
    "print(\"Missing columns from X_val_fe: \", [col for col in train_fe.columns if col not in X_val_fe.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7e68f7-bd86-4e0c-a74c-d8ec67dca3bc",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "23afd07e-c4c5-4998-b48d-41aa62bca0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ..., 585, 585, 585])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit_transform(train_df['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3c53de93-49d9-41a6-a134-e1316dfd3f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_fe\n",
    "y = y_train\n",
    "le = LabelEncoder()\n",
    "kfold_group = le.fit_transform(train_df['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca5ef84-92fe-41b9-a41e-7ee46f037b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "558d8531-096d-48bb-bfc2-1e9874db0697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'warnings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m     38\u001b[0m kfold_group \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mwarnings\u001b[49m\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m captured_warnings:\n\u001b[1;32m     41\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# Start the Optuna study\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'warnings' is not defined"
     ]
    }
   ],
   "source": [
    "def objective_lgbm(trial, X, y, kfold_group):\n",
    "    # Define hyperparameters to tune (these are for LightGBM, modify as needed for different models)\n",
    "    hyperparams = {\n",
    "        'objective': 'lambdarank',\n",
    "        'metric': 'ndcg',\n",
    "        'eval_at': [1, 10, 20, 30],\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.1, 0.2),\n",
    "        'num_iterations': trial.suggest_int('num_iterations', 50, 200), \n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 40),\n",
    "        'tree_learner': trial.suggest_categorical('tree_learner', ['serial', 'feature', 'data', 'voting']),\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    # Initialize GroupKFold\n",
    "    group_kfold = GroupKFold(n_splits=4)\n",
    "    scores = []\n",
    "\n",
    "    # Split the data and perform training and evaluation\n",
    "    for train_index, val_index in group_kfold.split(X, y, kfold_group):\n",
    "        X_train_, X_val_ = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train_, y_val_ = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        # Initialize and train the model\n",
    "        model = LGBMRanker(**hyperparams)\n",
    "        model.fit(X_train_, y_train_, group=groupper(train_index))  # Adjust for non-ranking models\n",
    "        \n",
    "        # Predictions and evaluation for each fold\n",
    "        y_pred = model.predict(X_val_)\n",
    "        score = roc_auc_score(y_val_, y_pred)\n",
    "        scores.append(score)\n",
    "\n",
    "    # Return the average score across all folds\n",
    "    return np.mean(scores)\n",
    "\n",
    "X = X_train_fe\n",
    "y = y_train\n",
    "le = LabelEncoder()\n",
    "kfold_group = le.fit_transform(train_df['query'])\n",
    "\n",
    "with warnings.catch_warnings(record=True) as captured_warnings:\n",
    "    warnings.simplefilter(\"always\")\n",
    "    \n",
    "    # Start the Optuna study\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective_lgbm(trial, X, y, kfold_group), n_trials=3)\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "print(f'Best parameters: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73658ce6-ae4d-4689-8858-d20cddc6ba22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c89023-e835-450d-ac3f-62ca6d3fb77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ffa5fc-08b3-4dfe-855d-cb98ff9a2ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cfa890-0da6-4314-81c8-2f1707323105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "def objective(trial, model_class, X, y, groups, score_func, additional_params=None):\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter tuning using Optuna.\n",
    "    Allows for the training and evaluation of different models.\n",
    "    \n",
    "    :param trial: Optuna trial object.\n",
    "    :param model_class: ML model class to be optimized.\n",
    "    :param X: Feature data.\n",
    "    :param y: Target labels.\n",
    "    :param groups: Group labels for ranking or other group-specific tasks.\n",
    "    :param score_func: Function used to calculate the score for model evaluation.\n",
    "    :param additional_params: Additional model parameters not being tuned.\n",
    "    \"\"\"\n",
    "    # Define hyperparameters to tune (these are for LightGBM, modify as needed for different models)\n",
    "    hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.1, 0.2),\n",
    "        'num_iterations': trial.suggest_int('num_iterations', 50, 200), \n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 40),\n",
    "        'tree_learner': trial.suggest_categorical('tree_learner', ['serial', 'feature', 'data', 'voting']), \n",
    "        'verbose': -1,\n",
    "    }\n",
    "    if additional_params:\n",
    "        hyperparams.update(additional_params)\n",
    "\n",
    "    # Initialize GroupKFold\n",
    "    group_kfold = GroupKFold(n_splits=4)\n",
    "    scores = []\n",
    "\n",
    "    # Split the data and perform training and evaluation\n",
    "    for train_index, val_index in group_kfold.split(X, y, groups):\n",
    "        X_train_, X_val_ = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train_, y_val_ = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        # Initialize and train the model\n",
    "        model = model_class(**hyperparams)\n",
    "        model.fit(X_train_, y_train_, group=groups[train_index])  # Adjust for non-ranking models\n",
    "        \n",
    "        # Predictions and evaluation for each fold\n",
    "        y_pred = model.predict(X_val_)\n",
    "        score = score_func(y_val_, y_pred)\n",
    "        scores.append(score)\n",
    "\n",
    "    # Return the average score across all folds\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Usage example\n",
    "X = X_train_fe  # Your feature data\n",
    "y = y_train  # Your target data\n",
    "le = LabelEncoder()\n",
    "groups = le.fit_transform(train_fe['query'])  # Your group data\n",
    "\n",
    "# For LightGBM ranking model\n",
    "from lightgbm import LGBMRanker\n",
    "additional_params = {'objective': 'lambdarank', 'metric': 'ndcg', 'eval_at': [1, 10, 20, 30]}\n",
    "\n",
    "# Start the Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(lambda trial: objective(trial, LGBMRanker, X, y, groups, roc_auc_score, additional_params), n_trials=3)\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "print(f'Best parameters: {best_params}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e9a87-7710-4b53-b77f-7ac6e0691bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c48ad-3e0b-45c8-807a-7ac9a7849821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602491b5-df1b-434b-bf88-0d458f99f5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70310836-5c10-4c42-9e0e-c64968c87681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fa6a69-a9c3-4f0c-8443-2abfef452b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb55607-dbda-4807-872a-149f51ba7dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4c4c1b-5d0c-4c5c-9006-b9c6fd17eb37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bd98e9-b4cd-4609-b0d4-4a3abb0f10a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_train_fe_used.columns\n",
    "coef = model.feature_importances_\n",
    "coef_df = pd.DataFrame({'Feature': col, 'Coefficient': coef})\n",
    "coef_df = coef_df.reindex(coef_df.Coefficient.abs().sort_values(ascending=False).index)\n",
    "\n",
    "plt.figure(figsize=(10, 6))  # You can adjust the figure size as per your requirements\n",
    "plt.barh(coef_df['Feature'], coef_df['Coefficient'], color='skyblue')  # Horizontal bar chart for better readability\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Importance of Features in Predicting Result (Gradient Boosting Feature Importance)')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature on top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38b6506-9064-48a8-b9a8-b2f7ccac3578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba66b0-3699-4bd4-8421-a44ef1ffa568",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = optuna.trial.Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5cbbbe-8d66-4a17-8517-12cd84535a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter tuning using Optuna.\n",
    "    Trains a LightGBM ranking model and evaluates using GroupKFold.\n",
    "    \"\"\"\n",
    "    # Define hyperparameters to tune\n",
    "    hyperparams = {\n",
    "        'objective': 'lambdarank',\n",
    "        'metric': 'ndcg',\n",
    "        'eval_at': [1, 10, 20, 30],\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.1, 0.2),\n",
    "        'num_iterations': trial.suggest_int('num_iterations', 50, 200), \n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 40), \n",
    "        # 'lambda_l1': trial.suggest_float('lambda_l1', 0.1, 0.9),\n",
    "        # 'lambda_l2': trial.suggest_float('lambda_l2', 0.1, 0.9),\n",
    "        'tree_learner': trial.suggest_categorical('tree_learner', ['serial', 'feature', 'data', 'voting']), \n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    # Input\n",
    "    X = X_train_fe\n",
    "    y = y_train\n",
    "    le = LabelEncoder()\n",
    "    kfold_group = le.fit_transform(train_fe['query'])\n",
    "\n",
    "    # Initialize GroupKFold\n",
    "    group_kfold = GroupKFold(n_splits=4)\n",
    "    scores = []\n",
    "\n",
    "    # Split the data and perform training and evaluation\n",
    "    for train_index, val_index in group_kfold.split(X, y, kfold_group):\n",
    "        X_train_, X_val_ = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train_, y_val_ = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        # Initialize and train the LightGBM ranker model\n",
    "        ranker = LGBMRanker(**hyperparams)\n",
    "        ranker.fit(X_train_, y_train_, group=groupper(train_index))\n",
    "        \n",
    "        # Predictions and evaluation for each fold\n",
    "        y_pred = ranker.predict(X_val_)\n",
    "        score = roc_auc_score(y_val_, y_pred)\n",
    "        scores.append(score)\n",
    "\n",
    "    # Return the average score across all folds\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# Start the Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=3)\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "print(f'{best_params=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a543d231-bbe8-4906-8ff3-af07995f854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRanker(**best_params)\n",
    "model.fit(X_train_fe_used, y_train, group=train_groups)\n",
    "\n",
    "y_pred_proba = model.predict(X_val_fe_used, group=val_groups)\n",
    "proba_to_predict = lambda proba, threshold=0.5: (proba > threshold).astype(int)\n",
    "y_pred = proba_to_predict(y_pred_proba)\n",
    "\n",
    "manual_auc_roc_draw(y_val, y_pred_proba)\n",
    "manual_pr_draw(y_val, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
